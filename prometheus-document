https://prometheus.io/docs/introduction/overview/

Prometheus is an open-source systems monitoring and alerting toolkit originally built at SoundCloud.

Prometheus collects and stores its metrics as time series data, i.e. metrics information is stored with the timestamp at which it was recorded,
alongside optional key-value pairs called labels.

Features
Prometheus's main features are:

a multi-dimensional data model with time series data identified by metric name and key/value pairs
PromQL, a flexible query language to leverage this dimensionality
no reliance on distributed storage; single server nodes are autonomous
time series collection happens via a pull model over HTTP
pushing time series is supported via an intermediary gateway
targets are discovered via service discovery or static configuration
multiple modes of graphing and dashboarding support

What are metrics ?
In layperson terms, metrics are numeric measurements, time series mean that changes are recorded over time. What users want to measure differs 
from application to application. For a web server it might be request times, for a database it might be number of active connections or number of active queries etc.

Metrics play an important role in understanding why your application is working in a certain way. Let's assume you are running a web application and find 
that the application is slow. You will need some information to find out what is happening with your application. For example the application can become slow when 
the number of requests are high. If you have the request count metric you can spot the reason and increase the number of servers to handle the load.

Components
The Prometheus ecosystem consists of multiple components, many of which are optional:

the main Prometheus server which scrapes and stores time series data
client libraries for instrumenting application code
a push gateway for supporting short-lived jobs
special-purpose exporters for services like HAProxy, StatsD, Graphite, etc.
an alertmanager to handle alerts


Prometheus is a full monitoring and trending system that includes built-in and active scraping, storing, querying, graphing, and alerting based on time series data. 
It has knowledge about what the world should look like (which endpoints should exist, what time series patterns mean trouble, etc.), and actively tries to find faults


Prometheus scrapes metrics from instrumented jobs, either directly or via an intermediary push gateway for short-lived jobs.
It stores all scraped samples locally and runs rules over this data to either aggregate and record new time series from existing data or generate alerts. 
Grafana or other API consumers can be used to visualize the collected data.


Download

https://prometheus.io/download/


Configuring Prometheus 

prometheus.yaml

global:
  scrape_interval:     15s
  evaluation_interval: 15s

rule_files:
  # - "first.rules"
  # - "second.rules"

scrape_configs:
  - job_name: prometheus
    static_configs:
      - targets: ['localhost:9090']     
      
---------------------------
There are three blocks of configuration in the example configuration file: global, rule_files, and scrape_configs.

The global block controls the Prometheus server's global configuration. We have two options present. The first, scrape_interval,
controls how often Prometheus will scrape targets. You can override this for individual targets. In this case the global setting is to scrape every 15 seconds.
The evaluation_interval option controls how often Prometheus will evaluate rules. Prometheus uses rules to create new time series and to generate alerts.

The rule_files 
->specifies the location of any rules we want the Prometheus server to load

scrape_configs
->controls what resources Prometheus monitors. 

Since Prometheus also exposes data about itself as an HTTP endpoint it can scrape and monitor its own health. In the default configuration there is a single job, 
called prometheus, which scrapes the time series data exposed by the Prometheus server. The job contains a single, statically configured, target, the localhost 
on port 9090. 
Prometheus expects metrics to be available on targets on a path of /metrics. 
So this default job is scraping via the URL: http://localhost:9090/metrics.


one metric that Prometheus exports about itself is called 

promhttp_metric_handler_requests_total 

(the total number of /metrics requests the Prometheus server has served)

This should return a number of different time series (along with the latest value recorded for each), all with the metric name promhttp_metric_handler_requests_total, but with different labels. These labels designate different requests statuses.

If we were only interested in requests that resulted in HTTP code 200, we could use this query to retrieve that information:

promhttp_metric_handler_requests_total{code="200"}

To count the number of returned time series, you could write:

count(promhttp_metric_handler_requests_total)

Where Prometheus is better:

If you're primarily doing metrics.
More powerful query language, alerting, and notification functionality.
Higher availability and uptime for graphing and alerting.


Nagios is suitable for basic monitoring of small and/or static systems where blackbox probing is sufficient.

If you want to do whitebox monitoring, or have a dynamic or cloud based environment, then Prometheus is a good choice.


ALERTING:
An alert is the outcome of an alerting rule in Prometheus that is actively firing. Alerts are sent from Prometheus to the Alertmanager.

Alertmanager
The Alertmanager takes in alerts, aggregates them into groups, de-duplicates, applies silences, throttles, and then sends out notifications to email, Pagerduty, Slack etc.

Exporter
An exporter is a binary running alongside the application you want to obtain metrics from. The exporter exposes Prometheus metrics,
commonly by converting metrics that are exposed in a non-Prometheus format into a format that Prometheus supports.

Job
A collection of targets with the same purpose, for example monitoring a group of like processes replicated for scalability or reliability, is called a job.

Pushgateway
The Pushgateway persists the most recent push of metrics from batch jobs. This allows Prometheus to scrape their metrics after they have terminated.


DATA MODEL

Prometheus fundamentally stores all data as time series: streams of timestamped values belonging to the same metric and the same set of labeled dimensions. 
Besides stored time series, Prometheus may generate temporary derived time series as the result of queries.
